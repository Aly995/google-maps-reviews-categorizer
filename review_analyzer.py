# -*- coding: utf-8 -*-

import csv
import json
import os
from collections import Counter
from typing import List, Dict, Tuple
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class ReviewAnalyzer:
    """
    Analyzes Google Maps reviews using OpenAI API to extract common positive and negative themes.
    """
    
    def __init__(self, api_key=None):
        """
        Initialize the analyzer with OpenAI API key.
        
        Args:
            api_key: OpenAI API key. If None, will try to load from OPENAI_API_KEY env variable.
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OpenAI API key not found. Set OPENAI_API_KEY environment variable or pass api_key parameter.")
        
        self.client = OpenAI(api_key=self.api_key)
    
    def read_reviews_from_csv(self, csv_path: str) -> List[Dict]:
        """
        Read reviews from CSV file generated by the scraper.
        
        Args:
            csv_path: Path to the CSV file
            
        Returns:
            List of review dictionaries
        """
        reviews = []
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # Handle both 'review_text' (from scraper) and 'Review' (alternative format)
                    review_text = row.get('review_text', '') or row.get('Review', '')
                    reviews.append({
                        'name': row.get('reviewer_name', '') or row.get('Name', ''),
                        'rating': row.get('rating', '') or row.get('Rating', ''),
                        'date': row.get('date', '') or row.get('Date', ''),
                        'review': review_text
                    })
            print(f"[INFO] Loaded {len(reviews)} reviews from {csv_path}")
            return reviews
        except Exception as e:
            print(f"[ERROR] Failed to read CSV: {e}")
            return []
    
    def identify_dynamic_categories(self, reviews: List[Dict]) -> Dict:
        """
        Extract up to 4 positive and 4 negative categories from a sample of reviews.
        """
        # Use a representative sample of reviews (up to 30)
        sample = [r for r in reviews if r['review'].strip()][:30]
        review_texts = [f"- {r['review']}" for r in sample]
        
        reviews_joined = "\n".join(review_texts)
        prompt = f"""Analyze these customer reviews and identify the 4 most prominent POSITIVE themes and the 4 most prominent NEGATIVE themes.
        
REVIEWS:
{reviews_joined}

INSTRUCTIONS:
1. Create exactly 4 broad but descriptive categories for POSITIVE feedback.
2. Create exactly 4 broad but descriptive categories for NEGATIVE feedback.
3. Categories should be concise (1-3 words).
4. Return ONLY a JSON object with this structure:
{{
  "positives": ["Category 1", "Category 2", "Category 3", "Category 4"],
  "negatives": ["Category 1", "Category 2", "Category 3", "Category 4"]
}}"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a professional feedback analyst."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            print(f"[ERROR] Failed to identify dynamic categories: {e}")
            return {
                "positives": ["Service", "Product", "Environment", "Value"],
                "negatives": ["Service Issues", "Product Issues", "Environment Issues", "Value Issues"]
            }

    def analyze_batch(self, reviews: List[Dict], dynamic_categories: Dict, batch_size: int = 20) -> Dict:
        """
        Analyze reviews in batches and map them to dynamic categories.
        """
        all_mappings = {'positives': {}, 'negatives': {}}
        for cat in dynamic_categories['positives']: all_mappings['positives'][cat] = []
        for cat in dynamic_categories['negatives']: all_mappings['negatives'][cat] = []
        
        for i in range(0, len(reviews), batch_size):
            batch = reviews[i:i + batch_size]
            print(f"[INFO] Analyzing batch {i//batch_size + 1}/{(len(reviews)-1)//batch_size + 1}...")
            
            review_data = []
            for idx, r in enumerate(batch):
                if r['review'].strip():
                    review_data.append({"id": i + idx, "text": r['review'], "rating": r['rating']})
            
            if not review_data: continue

            prompt = f"""Map each review to ONE of the provided categories. 
            
CATEGORIES TO USE:
{', '.join(dynamic_categories['positives'])}
{', '.join(dynamic_categories['negatives'])}

REVIEWS:
{json.dumps(review_data)}

INSTRUCTIONS:
1. For each review, select the BEST fitting category from the CATEGORIES TO USE list above.
2. YOU MUST USE THE EXACT CATEGORY NAMES LISTED AS KEYS IN YOUR JSON.
3. DO NOT use "Positives", "Negatives", or any other generic labels as keys.
4. Return a JSON object where keys are EXACT CATEGORY NAMES and values are lists of review IDs.
Format:
{{
  "Exact Category Name 1": [id1, id2, ...],
  "Exact Category Name 2": [id3, id4, ...],
  ...
}}"""

            try:
                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "You are a precise data classifier. Output ONLY JSON."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,
                    response_format={"type": "json_object"}
                )
                batch_mapping = json.loads(response.choices[0].message.content)
                
                # Merge into all_mappings with robust matching
                for ai_cat, ids in batch_mapping.items():
                    target_cat = None
                    sentiment = None
                    
                    # Case-insensitive search in positive categories
                    for cat in dynamic_categories['positives']:
                        if ai_cat.lower().strip() == cat.lower().strip():
                            target_cat = cat
                            sentiment = 'positives'
                            break
                    
                    # Case-insensitive search in negative categories if not found in positives
                    if not target_cat:
                        for cat in dynamic_categories['negatives']:
                            if ai_cat.lower().strip() == cat.lower().strip():
                                target_cat = cat
                                sentiment = 'negatives'
                                break
                    
                    if target_cat:
                        # Ensure IDs are integers for Python (though JS handles strings)
                        clean_ids = [int(id_val) for id_val in ids if str(id_val).isdigit()]
                        all_mappings[sentiment][target_cat].extend(clean_ids)
                    else:
                        print(f"[DEBUG] Category '{ai_cat}' not found in dynamic themes")
                        
            except Exception as e:
                print(f"[ERROR] Batch analysis failed: {e}")
                continue
        
        return all_mappings

    def _create_analysis_prompt(self, review_texts: List[str]) -> str:
        """Deprecated in favor of dynamic mapping."""
        return ""
    
    def _parse_analysis_response(self, response_text: str) -> Dict:
        """Parse the JSON response from OpenAI."""
        try:
            # Try to extract JSON from the response
            response_text = response_text.strip()
            
            # Remove markdown code blocks if present
            if response_text.startswith('```'):
                lines = response_text.split('\n')
                response_text = '\n'.join(lines[1:-1])
            
            result = json.loads(response_text)
            return {
                'positives': result.get('positives', []),
                'negatives': result.get('negatives', [])
            }
        except json.JSONDecodeError as e:
            print(f"[ERROR] Failed to parse API response: {e}")
            print(f"[DEBUG] Response text: {response_text}")
            return {'positives': [], 'negatives': []}
    
    def _aggregate_themes(self, mapping: Dict, reviews: List[Dict]) -> Dict:
        """Aggregate data and include full review objects for the dashboard."""
        results = {
            'positives': [],
            'negatives': [],
            'total_positive_mentions': 0,
            'total_negative_mentions': 0,
            'review_data': reviews # Keep original reviews for lookup
        }
        
        for cat, ids in mapping['positives'].items():
            count = len(ids)
            results['positives'].append((cat, count, ids))
            results['total_positive_mentions'] += count
            
        for cat, ids in mapping['negatives'].items():
            count = len(ids)
            results['negatives'].append((cat, count, ids))
            results['total_negative_mentions'] += count
            
        # Sort by count
        results['positives'].sort(key=lambda x: x[1], reverse=True)
        results['negatives'].sort(key=lambda x: x[1], reverse=True)
        
        return results
    
    def generate_report(self, analysis_results: Dict, business_name: str = "Business") -> str:
        """
        Generate a formatted text report from analysis results.
        
        Args:
            analysis_results: Dictionary from analyze_batch()
            business_name: Name of the business being analyzed
            
        Returns:
            Formatted report string
        """
        report = []
        report.append("=" * 70)
        report.append(f"REVIEW ANALYSIS REPORT: {business_name}")
        report.append("=" * 70)
        report.append("")
        
        # Summary statistics
        total_pos = analysis_results['total_positive_mentions']
        total_neg = analysis_results['total_negative_mentions']
        total = total_pos + total_neg
        
        if total > 0:
            pos_percentage = (total_pos / total) * 100
            neg_percentage = (total_neg / total) * 100
            
            report.append("OVERALL SENTIMENT")
            report.append("-" * 70)
            report.append(f"Positive mentions: {total_pos} ({pos_percentage:.1f}%)")
            report.append(f"Negative mentions: {total_neg} ({neg_percentage:.1f}%)")
            report.append("")
        
        # Top positive themes
        report.append("TOP POSITIVE THEMES")
        report.append("-" * 70)
        if analysis_results['positives']:
            for idx, (theme, count, _) in enumerate(analysis_results['positives'], 1):
                report.append(f"{idx:2d}. {theme.title():<40} (mentioned {count} times)")
        else:
            report.append("No positive themes identified")
        report.append("")
        
        # Top negative themes
        report.append("TOP NEGATIVE THEMES")
        report.append("-" * 70)
        if analysis_results['negatives']:
            for idx, (theme, count, _) in enumerate(analysis_results['negatives'], 1):
                report.append(f"{idx:2d}. {theme.title():<40} (mentioned {count} times)")
        else:
            report.append("No negative themes identified")
        report.append("")
        
        report.append("=" * 70)
        
        return "\n".join(report)
    
    def analyze_reviews_from_csv(self, csv_path: str, output_path: str = None) -> Dict:
        """
        Main method to analyze reviews from a CSV file.
        
        Args:
            csv_path: Path to the CSV file
            output_path: Optional path to save the report (txt file)
            
        Returns:
            Analysis results dictionary
        """
        # Read reviews
        reviews = self.read_reviews_from_csv(csv_path)
        
        if not reviews:
            print("[ERROR] No reviews to analyze")
            return {}
        
        # Analyze reviews
        print(f"[INFO] Identifying dynamic categories...")
        dynamic_cats = self.identify_dynamic_categories(reviews)
        print(f"[INFO] Categories identified: {dynamic_cats}")
        
        print(f"[INFO] Starting analysis of {len(reviews)} reviews...")
        mapping = self.analyze_batch(reviews, dynamic_cats)
        results = self._aggregate_themes(mapping, reviews)
        
        # Extract business name from CSV filename
        business_name = os.path.splitext(os.path.basename(csv_path))[0].replace('_reviews', '').replace('-', ' ').title()
        
        # Generate report
        report = self.generate_report(results, business_name)
        
        # Print to console
        print("\n" + report)
        
        # Save to file if requested
        if output_path:
            try:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(report)
                print(f"\n[INFO] Report saved to: {output_path}")
            except Exception as e:
                print(f"[ERROR] Failed to save report: {e}")
        
        # Also save JSON results
        json_path = csv_path.replace('.csv', '_analysis.json')
        try:
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            print(f"[INFO] JSON results saved to: {json_path}")
        except Exception as e:
            print(f"[ERROR] Failed to save JSON: {e}")
        
        # Generate HTML dashboard
        try:
            from dashboard_generator import generate_html_dashboard
            dashboard_path = generate_html_dashboard(results, business_name, csv_path)
            
            if dashboard_path:
                # Auto-open dashboard in browser
                import webbrowser
                print(f"[INFO] Opening dashboard in browser...")
                webbrowser.open('file://' + os.path.abspath(dashboard_path))
        except ImportError:
            print("[WARNING] Dashboard generator not found. Skipping HTML dashboard generation.")
        except Exception as e:
            print(f"[WARNING] Failed to generate dashboard: {e}")
        
        return results
